{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b289921",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (52926467.py, line 294)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.close('all')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 15 17:21:40 2021\n",
    "\n",
    "@author: menglu\n",
    "\"\"\"\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "from rasterstats import zonal_stats, point_query\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "import modelutils as m\n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import show_hist\n",
    "from math import modf\n",
    "import osmnx as ox\n",
    "from scipy import signal \n",
    "wuhan = ox.geocode_to_gdf('武汉, China')\n",
    "utrecht = ox.geocode_to_gdf('Utrecht province') \n",
    "utrecht.plot() \n",
    "filedir = \"/Users/menglu/Documents/GitHub/mobiair/\"\n",
    "preddir =f\"{filedir}prediction/\"\n",
    "\n",
    "savedir = \"/Volumes/Meng_Mac/mobi_result/Uni/\" # each profile a savedir. \n",
    "                   \n",
    "def wgs2laea (p):\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    rd= pyproj.CRS('+proj=laea +lat_0=51 +lon_0=9.5 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs')\n",
    "    project = pyproj.Transformer.from_crs(wgs84, rd, always_xy=True)\n",
    "    p=transform(project.transform, p)\n",
    "    return (p)  \n",
    "\n",
    "def plot_raster ():\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=6, figsize=(55,15)) \n",
    "                            \n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        src = rasterio.open(f'{preddir}NL100_t{i}.tif')\n",
    "\n",
    "        ax.set_axis_off()\n",
    "        a=ax.imshow(src.read(1), cmap='pink')\n",
    "        ax.set_title(f' {i:02d}:00')\n",
    "         \n",
    "    cbar = fig.colorbar(a, ax=axs.ravel().tolist())\n",
    "    cbar.set_label(r'$NO_2$', rotation = 270)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#plt.savefig(savedir+\"prediUt.png\")\n",
    "\n",
    "#show_hist(src, bins=50, histtype='stepfilled', lw=0.0, stacked=False, alpha=0.3)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "#ls = os.listdir(preddir)\n",
    "\n",
    "def gethw (df):\n",
    "    ph=Point(float(df.home_lon) , float(df.home_lat) )\n",
    "    ph = wgs2laea(ph)\n",
    "    pw=Point(float(df.work_lon) , float(df.work_lat) )\n",
    "    pw = wgs2laea(pw)\n",
    "    return(ph, pw)\n",
    "\n",
    "def buffermean(p, ext , rasterfile):\n",
    "   \n",
    "    pbuf=p.buffer(ext)\n",
    "    z= zonal_stats(pbuf, rasterfile, stats = 'mean')[0]['mean']\n",
    "    \n",
    "    return z  \n",
    "\n",
    "\n",
    "def gkern(kernlen=21, std=3):\n",
    "    \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
    "    gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen, 1)\n",
    "    gkern2d = np.outer(gkern1d, gkern1d)\n",
    "    return gkern2d\n",
    "\n",
    "\n",
    "#plt.imshow(gkern(2000,500))\n",
    "    \n",
    "#extract pollution map in the buffer and convolve with gaussian kernel.  \n",
    "def gaussKernconv(p, ext , rasterfile, sd = 1):\n",
    "   \n",
    "    pbuf=p.buffer(ext)\n",
    "    getras= zonal_stats(pbuf,rasterfile ,stats=\"count\", raster_out=True)[0]['mini_raster_array']\n",
    " \n",
    "    ag = gkern (getras.data.shape[0], sd)\n",
    "    \n",
    "    z = signal.convolve2d(getras.data,ag, mode = 'valid') # valid does not pad. \n",
    "      \n",
    "    return z  \n",
    "\n",
    "\n",
    "''' for testing\n",
    "j =1\n",
    "homework.loc[j]\n",
    "ph, pw = gethw(homework.loc[j])\n",
    "rasterfile =f'{preddir}NL100_t{1}.tif'\n",
    "buffermean(ph, 300, rasterfile)\n",
    "p = ph\n",
    "''' \n",
    "\n",
    "\n",
    "\n",
    "def getconcen(act_num, rasterfile, df, routegeom, ext = 100, extgaus = 2000, sd=300, indoor_ratio = 0.7 ):\n",
    "    ph, pw = gethw(df)\n",
    "    return {\n",
    "       1: indoor_ratio * point_query(ph, rasterfile ).pop(), #home\n",
    "       2: np.nan_to_num(np.mean(point_query(routegeom, rasterfile)),0),# route #can easily make buffer out of it as well, here the ap already 100m so not needed.\n",
    "       3: indoor_ratio *point_query(pw, rasterfile ).pop(), # work_indoor\n",
    "       4: buffermean(p, ext, rasterfile), # freetime 1 will change into to sport (second route)\n",
    "       5: gaussKernconv(p, extgaus, rasterfile, sd = 1), # freetime 2, distance decay, outdoor. \n",
    "       6: buffermean(p, ext, rasterfile)  # freetime 3, in garden or terras  \n",
    "       } [act_num]                                              \n",
    "\n",
    "#schefile = os.listdir(schedir)\n",
    " \n",
    "\n",
    " \n",
    "# rasterfile = f'{preddir}NL100_t{i}.tif'\n",
    "\n",
    "def remove_none(nparray): \n",
    "    arr = np.array(nparray)\n",
    "    return(arr[arr!= np.array( None)])\n",
    "'''  \n",
    "#test\n",
    "for i in range(1,7):\n",
    "    getconcen(act_num= i,\n",
    "              rasterfile=f'{preddir}NL100_t{i}.tif', \n",
    "              df = Uni_ut_homework.loc[j], \n",
    "              routegeom=route.loc[j]['geometry'])\n",
    "'''\n",
    "#still doing hourly\n",
    "ext = 300 # 300 m \n",
    "iteration = 1\n",
    "\n",
    "ODdir = savedir +\"genloc/\"\n",
    "ODfile =f'h2w_{iteration}.csv' \n",
    "homework =gpd.read_file(ODdir+ODfile) # for comparison #gpd can read csv as well, just geom as None.\n",
    "\n",
    "def cal_exp(filedir, savedir, iteration, ext = 100, extgaus=2000, gaussd = 300,  save_csv = True):\n",
    "    ODdir = savedir +\"genloc/\"\n",
    "    ODfile =f'h2w_{iteration}.csv' \n",
    "    homework =gpd.read_file(ODdir+ODfile) # for comparison #gpd can read csv as well, just geom as None.\n",
    "    routedir = savedir+'genroute/'\n",
    "    routefile = f'route_{iteration}.gpkg' # get route file for all people, only one route file,geodataframe\n",
    "    route= gpd.read_file(routedir+routefile)\n",
    "    route = route.to_crs('+proj=laea +lat_0=51 +lon_0=9.5 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs')\n",
    "    \n",
    "    schedir = savedir+'gensche/'\n",
    "    # exp is concentration weighted by time duration\n",
    "    exp_each_act = []\n",
    "    exp_each_person= []\n",
    "    n = len(homework)\n",
    "    for j in range(n): #iterate over each person\n",
    "    \n",
    "        sched = pd.read_csv(f'{schedir}ws_iter_1_id_{j}.csv') #each person has a schedule, only schedule is file per person.\n",
    "        start = sched['start_time']\n",
    "        end =sched['end_time']\n",
    "        start_int=np.floor(start).astype(int)\n",
    "        end_int = np.ceil(end).astype(int) # for using range, actually np.floor ()\n",
    "        act_num = sched['activity_code']\n",
    "        \n",
    "        for k in range(sched.shape[0]): # iterate over schedule\n",
    "            conh = 0 # hourly concentration for each activity\n",
    "            missingtimeh = 0 \n",
    "            missingtime = 0\n",
    "            if start_int[k] == end_int[k]-1: # less than one hour\n",
    "                    con = getcon(act_num[k], f'{preddir}NL100_t{start_int[k]}.tif',  homework.loc[j], route.loc[j]['geometry'], ext = ext, extgaus = extgaus, sd = gaussd)\n",
    "                    if con is not None or con is not np.nan:\n",
    "                        conh = con * (end[k]-start[k]) # start percentage multiply by concentration of the hour, next hour will get the rest of the percentage\n",
    "                        missingtimeh=0\n",
    "                    else: \n",
    "                        conh = 0\n",
    "                        missingtimeh = end[k]-start[k]\n",
    "                 \n",
    "            else: # more than one hour\n",
    "                for i in range(start_int[k],end_int[k]): # iterate over raster\n",
    "                    con = getcon(act_num[k], f'{preddir}NL100_t{i}.tif', homework.loc[j], route.loc[j]['geometry'], ext = ext, extgaus = extgaus, sd = gaussd)\n",
    "                    if i ==start_int[k]: # first hour may be from e.g. 7:20 instead of 7:00\n",
    "                        if con is not None or con is not np.nan:\n",
    "                            cons = con * (1- modf(start[k])[0]) # start percentage multiply by concentration of the hour, next hour will get the rest of the percentage\n",
    "                            missingtime=0\n",
    "                        else: \n",
    "                            cons = 0\n",
    "                            missingtime = modf(start[k])[0]\n",
    "                    elif i == end_int[k]: # last hour may be to e.g. 9:20 instead of 9:00\n",
    "                        if con is not None or con is not np.nan:\n",
    "                            cons = con * modf(end[k])[0] # end percentage\n",
    "                            missingtime=0\n",
    "                        else: # for none values or nan, assign valye 0 and note missing times\n",
    "                            cons = 0\n",
    "                            missingtime = modf(end[k])[0]               \n",
    "                    else:\n",
    "                        if con is not None or con is not np.nan:\n",
    "                            cons = con # middle times\n",
    "                            missingtime=0\n",
    "                        else: # for none values or nan, assign valye 0 and note missing times\n",
    "                            cons = 0\n",
    "                            missingtime = end_int - start_int  -1          \n",
    "    \n",
    "                    \n",
    "                # summing exposures\n",
    "                    conh= conh +cons\n",
    "                    #exp_each_hour.append(cons)\n",
    "                    missingtimeh = missingtimeh + missingtime \n",
    "                    \n",
    "            exp = conh/(end[k]-start[k]-missingtimeh+0.01) # average exp per activity\n",
    "            exp_each_act.append(exp)\n",
    "            #con_each_person.append(np.nanmean(remove_none(con_each_act[k*j : (k+1)*j ]) ))      \n",
    "        exp_each_person.append(np.nanmean(remove_none(con_each_act[j*sched.shape[0]:(j+1)*sched.shape[0]])))\n",
    "        print(j)\n",
    "    \n",
    "    if save_csv:\n",
    "        exposuredir =f\"{savedir}exposure/\" \n",
    "        m.makefolder(exposuredir)    \n",
    "        pd.DataFrame(exp_each_act).to_csv(f'{exposuredir}iter_{iteration}_act.csv')\n",
    "        pd.DataFrame(exp_each_person).to_csv(f'{exposuredir}iter_{iteration}_person.csv')\n",
    "    return (exp_each_act, exp_each_person)    \n",
    "      \n",
    "#act, person = cal_exp(filedir, savedir, iteration, save_csv = True)\n",
    "act = pd.read_csv(f\"{savedir}exposure/iter_{1}_act.csv\").iloc[:,1]\n",
    "person = pd.read_csv(f\"{savedir}exposure/iter_{1}_person.csv\").iloc[:,1]\n",
    "\n",
    "# plot\n",
    "def formattime(timeinput): \n",
    "  \n",
    "    minute, hour = modf(timeinput)\n",
    "    minute = np.floor(minute *60)     \n",
    "    return \"%02d:%02d\" % (hour, minute) \n",
    "\n",
    "def plotact(sub1, sub2,  savename=\"1\",act = act, simplify = True, select = 0):\n",
    "    \n",
    "    schedir = savedir+'gensche/'\n",
    "\n",
    "    fig, ax = plt.subplots(sub1,sub2,figsize=(18, 56), sharey=True )\n",
    "    axs = ax.flatten()\n",
    "    for i1 in range (sub1*sub2):\n",
    "            i = i1 + select\n",
    "            sch = pd.read_csv(f'{schedir}ws_iter_1_id_{i}.csv')\n",
    "            st = sch['start_time']\n",
    "            et = sch['end_time']\n",
    "            axs[i1].plot(list(st),act[i*7:(i+1)*7], \"ko-\") \n",
    "            #st= np.round(st,1)\n",
    "            ind = np.where(np.diff(st)<1.5)[0]\n",
    "            if simplify:\n",
    "                xlabels = list(sch['activity'])\n",
    "            else:\n",
    "                xlabels = [f\"{x3}: {x1} to {x2}\" for x1, x2, x3, in zip(map(formattime,list(st)),map(formattime,list(et)),list(sch['activity']))]\n",
    "            \n",
    "            for j in range(7):\n",
    "                x, y = st[j],list(act[i*7:(i+1)*7])[j] \n",
    "                t = axs[i1].text(x, y+2, xlabels[j] )\n",
    "            #list(sch['activity'])[j] \n",
    "            et = et.drop(ind)\n",
    "            st=st.drop(ind)\n",
    "            #xlabels = [f\"{x1} to \\n{x2}\" for x1, x2, in zip(map(formattime,st), map(formattime,et))]\n",
    "            axs[i1].set_title(f'person ID: {i}')\n",
    "            axs[i1].set_xlabel('hour')\n",
    "            axs[i1].set_xticks(st) \n",
    "            axs[i1].set_xticklabels(map(formattime,st))\n",
    "            axs[i1].tick_params(axis='x',labelrotation =45,bottom=True,length=5)\n",
    "            axs[i1].set_ylabel(\"Exposure: \" r'$ \\mathrm{NO}_2$', fontsize=10)\n",
    "    #fig.supxlabel(\"hour\")\n",
    "    #fig.supylabel(\"Exposure: \" r'$ \\mathrm{NO}_2$', fontsize=10)\n",
    "    fig.tight_layout()      \n",
    "    fig.savefig(f'{savedir}exposure_act{savename}.png') \n",
    "plotact(sub1 = 2, sub2 =4, savename=\"more\", simplify=True, select = 2)    \n",
    "# people\n",
    "lat = np.array(homework.home_lat).astype(float)\n",
    "lon = np.array(homework.home_lon).astype(float)\n",
    " \n",
    "df1 = [person,lat, lon]\n",
    " \n",
    "df2 = pd.DataFrame(data=df1).T\n",
    "df2 = df2.rename (columns = {'0':\"personal_exposure\", \"Unnamed 0\": \"lat\", \"Unnamed 1\": \"lon\" })\n",
    "exp_gdf = gpd.GeoDataFrame(df2[\"personal_exposure\"], crs={'init': 'epsg:4326'},\n",
    "                                     geometry=[Point(xy) for xy in zip(df2.lon, df2.lat)])\n",
    "\n",
    "exp_gdf.to_file(f'{savedir}person_iter{iteration}.gpkg')\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "exp_gdf.plot(ax=ax, column = 'personal_exposure',legend=True)\n",
    "#\n",
    "#src = rasterio.open(f'{preddir}NL100_t{i}.tif')\n",
    "ax.imshow(src.read())\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()\n",
    " plt.close('all')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f73e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
